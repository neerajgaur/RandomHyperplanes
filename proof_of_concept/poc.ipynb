{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Proof of concept for the random-cut-hyperplanes idea \"\"\"\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.stats import scoreatpercentile\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "N_ESTIMATORS = 100\n",
    "SCORE_AT = 2.5\n",
    "\n",
    "# sys.setrecursionlimit(50000)\n",
    "\n",
    "# Steps for the algorithm\n",
    "#\n",
    "# Given a dataset, X:\n",
    "#   1. Get the feature ranges for each feature within X.\n",
    "#   2. Sample a random point between each feature.\n",
    "#   3. Create a hyperplane using each of these points.\n",
    "#   4. Get the normal to that plane.\n",
    "#   5. Determine which side of the plane the point lies on.\n",
    "#   6. Repeat for the two sides.\n",
    "#   7. If an individual point is left, stop iteration\n",
    "#\n",
    "class IsolationForest(object):\n",
    "    def __init__(self, n_estimators=10):\n",
    "        self.n_estimators = n_estimators\n",
    "\n",
    "    def fit(self, points):\n",
    "        self.trees = []\n",
    "        for i in range(self.n_estimators):\n",
    "            self.trees.append(IsolationTree(points))\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, points):\n",
    "        depths = np.array([tree.decision_function(points) for tree in self.trees])\n",
    "        mean_depths = np.mean(depths, axis=0)\n",
    "        # Normalize the points\n",
    "        scores = 2**-(mean_depths / average_path_length(points.shape[0]))\n",
    "        return scores\n",
    "\n",
    "    def get_depths(self, points):\n",
    "        depths = np.array([tree.decision_function(points) for tree in self.trees])\n",
    "        mean_depths = np.mean(depths, axis=0)\n",
    "        return mean_depths\n",
    "\n",
    "\n",
    "class IsolationTree(object):\n",
    "    def __init__(self, points, group_threshold=15, depth=1):\n",
    "        self.child_left = self.child_right = None\n",
    "        self.points = points\n",
    "        self.group_threshold = group_threshold\n",
    "        self.num_points = self.points.shape[0]\n",
    "        self.split(self.points, depth)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<{self.__class__.__name__} num_points:{self.num_points}>\"\n",
    "\n",
    "    @property\n",
    "    def is_leaf(self):\n",
    "        return self.child_left == None and self.child_right == None\n",
    "\n",
    "    def split(self, points, depth=1):\n",
    "        node, points_left, points_right = self.get_split(points)\n",
    "\n",
    "        if not node or depth >= 50:\n",
    "            return self\n",
    "\n",
    "        self.node = node\n",
    "        self.child_left = IsolationTree(points_left, depth=depth + 1)\n",
    "        self.child_right = IsolationTree(points_right, depth=depth + 1)\n",
    "\n",
    "    def decision_function(self, points):\n",
    "        return np.array([self.get_depth(point) for point in points])\n",
    "\n",
    "    def get_depth(self, point):\n",
    "        if self.is_leaf:\n",
    "            return 1\n",
    "        else:\n",
    "            if self.node.is_point_left(point):\n",
    "                return 1 + self.child_left.get_depth(point)\n",
    "            else:\n",
    "                return 1 + self.child_right.get_depth(point)\n",
    "\n",
    "    def get_split(self, points):\n",
    "        if self.num_points <2:\n",
    "            return (None, None, None)\n",
    "        split_feature = sample_feature(points)\n",
    "        split_threshold = sample_split_threshold(points, split_feature)\n",
    "        node = Node(split_threshold, split_feature)\n",
    "\n",
    "        positions = node.position_of_points(points)\n",
    "\n",
    "        points_left = points[positions]\n",
    "        points_right = points[np.logical_not(positions)]\n",
    "\n",
    "        return (node, points_left, points_right)\n",
    "\n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self, threshold, feature):\n",
    "        self.threshold = threshold\n",
    "        self.feature = feature\n",
    "\n",
    "    def is_point_left(self, point):\n",
    "        return point[self.feature] < self.threshold\n",
    "\n",
    "    def position_of_points(self, points):\n",
    "        return np.array([self.is_point_left(point) for point in points])\n",
    "\n",
    "\n",
    "class RandomHyperplanes(object):\n",
    "    def __init__(self, n_estimators=10):\n",
    "        self.n_estimators = n_estimators\n",
    "\n",
    "    def fit(self, points):\n",
    "        self.planes = []\n",
    "        for i in range(self.n_estimators): \n",
    "            self.planes.append(HyperplaneCollection(points))\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, points):\n",
    "        depths = np.array([plane.decision_function(points) for plane in self.planes])\n",
    "        mean_depths = np.mean(depths, axis=0)\n",
    "        # Normalize the points\n",
    "        scores = 2**-(mean_depths / average_path_length(points.shape[0]))\n",
    "        return scores\n",
    "\n",
    "    def get_depths(self, points):\n",
    "        depths = np.array([plane.decision_function(points) for plane in self.planes])\n",
    "        mean_depths = np.mean(depths, axis=0)\n",
    "        return mean_depths\n",
    "\n",
    "\n",
    "class HyperplaneCollection(object):\n",
    "    def __init__(self, points, group_threshold=15, depth=1):\n",
    "        self.child_left = self.child_right = None\n",
    "        self.points = points\n",
    "        self.group_threshold = group_threshold\n",
    "        self.num_points = self.points.shape[0]\n",
    "        self.split(self.points, depth)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<{self.__class__.__name__} num_points:{self.num_points}>\"\n",
    "\n",
    "    @property\n",
    "    def is_leaf(self):\n",
    "        return self.child_left == None and self.child_right == None\n",
    "\n",
    "    def split(self, points, depth=1):\n",
    "        plane, points_left, points_right = self.get_split(points)\n",
    "        if not plane or depth >= 50:\n",
    "            return self\n",
    "        self.splitting_plane = plane\n",
    "        self.child_left = HyperplaneCollection(points_left, depth=depth + 1)\n",
    "        self.child_right = HyperplaneCollection(points_right, depth=depth + 1)\n",
    "\n",
    "    def decision_function(self, points):\n",
    "        return np.array([self.get_depth(point) for point in points])\n",
    "\n",
    "    def get_depth(self, point):\n",
    "        if self.is_leaf:\n",
    "            return 1\n",
    "        else:\n",
    "            if self.splitting_plane.point_relative_to_plane(point) < 0:\n",
    "                return 1 + self.child_left.get_depth(point)\n",
    "            else:\n",
    "                return 1 + self.child_right.get_depth(point)\n",
    "\n",
    "    def get_split(self, points):\n",
    "        if self.num_points < 2:\n",
    "            return (None, None, None)\n",
    "        \n",
    "        splitting_plane = generate_splitting_plane(points)\n",
    "        positions = splitting_plane.position_of_points(points)\n",
    "        # split_point = np.random.uniform(np.min(positions), np.max(positions))\n",
    "        \n",
    "        points_left = points[np.where(positions < 0)]\n",
    "        points_right = points[np.where(positions > 0)]\n",
    "        return (splitting_plane, points_left, points_right)\n",
    "\n",
    "\n",
    "class Hyperplane(object):\n",
    "    def __init__(self, origin, normal):\n",
    "        self.origin = origin\n",
    "        self.normal = normal\n",
    "\n",
    "    def point_relative_to_plane(self, point):\n",
    "        return np.dot(self.normal, point - self.origin)\n",
    "\n",
    "    def position_of_points(self, points):\n",
    "        position = np.array([self.point_relative_to_plane(point) for point in points])\n",
    "        return position\n",
    "\n",
    "\n",
    "def sample_feature(point):\n",
    "    length = point.shape[-1]\n",
    "    return np.random.randint(low=0, high=length)\n",
    "\n",
    "def sample_split_threshold(points, feature):\n",
    "    return list(generate_point(points))[feature]\n",
    "\n",
    "def average_path_length(n):\n",
    "    return 2 * harmonic_approx(n - 1) - (2 * (n - 1) / n)\n",
    "\n",
    "def harmonic_approx(n):\n",
    "    return np.log(n) + 0.5772156649\n",
    "\n",
    "def generate_splitting_plane(points):\n",
    "    feature_ranges = get_feature_ranges(points)\n",
    "    origin = np.fromiter(generate_point(points), dtype=float)\n",
    "    \n",
    "    normal = np.fromiter(generate_point(points), dtype=float)\n",
    "    normal -= origin\n",
    "    \n",
    "    return Hyperplane(origin=origin, normal=normal)\n",
    "    \n",
    "def generate_point(points):\n",
    "    \"\"\" Generat an n-dimensional normal vector\n",
    "\n",
    "    For now just do so by sampling the points from a uniform distribution.\n",
    "    \"\"\"\n",
    "    feature_mins_maxes = get_feature_ranges(points)\n",
    "    for min_, max_, in get_feature_ranges(points):\n",
    "        yield np.random.uniform(low=min_, high=max_)\n",
    "\n",
    "def get_feature_ranges(points):\n",
    "    \"\"\" Yields the min and max of each feature in a vector. \"\"\"\n",
    "    points_transpose = np.transpose(points)\n",
    "    for point in points_transpose:\n",
    "        yield (np.min(point), np.max(point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _gen_hard_data(n, p, infection_pct, variance=10.0, mu=5.0):\n",
    "    X = np.random.randn(n, p)\n",
    "\n",
    "    # hard data\n",
    "    # Weight it to the number of features\n",
    "    is_anomaly = np.random.rand(n, p) < (infection_pct / p)\n",
    "    X[is_anomaly] = variance * np.random.randn() + mu\n",
    "\n",
    "    y = np.zeros(shape=(n,))\n",
    "\n",
    "    tmp = np.array([np.any(r) for r in is_anomaly])\n",
    "    y[tmp] = 1.0\n",
    "\n",
    "    return (X, y)\n",
    "\n",
    "def _gen_easy_data(n, p, infection_pct, variance=10.0, mu=5.0):\n",
    "    X = np.random.randn(n, p)\n",
    "    is_anomaly = np.random.choice(n, size=int(infection_pct*n), replace=False)\n",
    "    X[is_anomaly] = variance * np.random.randn(is_anomaly.shape[0], p) + mu\n",
    "    y = np.zeros(shape=(n,))\n",
    "    y[is_anomaly] = 1.0\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_plane_simul(points, y):\n",
    "    print(\"Beginning plane fit...\")\n",
    "    rhp = RandomHyperplanes(n_estimators=N_ESTIMATORS)\n",
    "    rhp = rhp.fit(points)\n",
    "    print(\"done fitting\")\n",
    "\n",
    "    scores = rhp.decision_function(points)\n",
    "    threshold = scoreatpercentile(scores, 100 - SCORE_AT)\n",
    "    anomalies = scores >= threshold\n",
    "    y_pred = np.zeros(shape=anomalies.shape)\n",
    "    y_pred[anomalies] = 1\n",
    "    \n",
    "    \"\"\"\n",
    "    correct_guesses = np.count_nonzero(y[np.where(scores <= threshold)])\n",
    "    incorrect_guesses = y[np.where(scores <= threshold)].shape[0] - \\\n",
    "        correct_guesses\n",
    "\n",
    "    print(\"Correct guesses:\", correct_guesses)\n",
    "    print(\"Incorrect guesses:\", incorrect_guesses)\n",
    "    print(\"Expected\", np.count_nonzero(y), \"anomalies\")\n",
    "    \"\"\"\n",
    "    cnf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = cnf_matrix.ravel()\n",
    "    print(f\"tp: {tp} \\ntn: {tn} \\nfp: {fp} \\nfn: {fn}\")\n",
    "    \"\"\"\n",
    "    cnf_matrix = cnf_matrix.astype('float') / \\\n",
    "        cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = cnf_matrix.ravel()\n",
    "    print(f\"Normalized \\ntp: {tp} \\ntn: {tn} \\nfp: {fp} \\nfn: {fn}\")\n",
    "    \"\"\"\n",
    "    print(cnf_matrix)\n",
    "\n",
    "    depths = rhp.get_depths(points)\n",
    "    anomalous_depths = depths[np.where(y==1.0)]\n",
    "    print(\"Average anomalous depth:\", np.mean(anomalous_depths))\n",
    "\n",
    "    non_anomalous_depths = depths[np.where(y==0.0)]\n",
    "    print(\"Average non-anomalous depth:\", np.mean(non_anomalous_depths))\n",
    "    return (scores, depths, y_pred, y)\n",
    "\n",
    "\n",
    "def run_iforest_simul(points, y):\n",
    "    print(\"Beginning iforest fit...\")\n",
    "    iforest = IsolationForest(n_estimators=N_ESTIMATORS)\n",
    "    iforest = iforest.fit(points)\n",
    "    print(\"done fitting\")\n",
    "\n",
    "    scores = iforest.decision_function(points)\n",
    "    threshold = scoreatpercentile(scores, 100 - SCORE_AT)\n",
    "    anomalies = scores >= threshold\n",
    "    y_pred = np.zeros(shape=anomalies.shape)\n",
    "    y_pred[anomalies] = 1\n",
    "\n",
    "    \"\"\"\n",
    "    correct_guesses = np.count_nonzero(y[np.where(scores <= threshold)])\n",
    "    incorrect_guesses = y[np.where(scores <= threshold)].shape[0] - \\\n",
    "        correct_guesses\n",
    "\n",
    "    print(\"iforest Correct guesses:\", correct_guesses)\n",
    "    print(\"iforest Incorrect guesses:\", incorrect_guesses)\n",
    "    print(\"Expected\", np.count_nonzero(y), \"anomalies\")\n",
    "    \"\"\"\n",
    "    iforest_cnf_matrix = confusion_matrix(y, y_pred)\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = iforest_cnf_matrix.ravel()\n",
    "    print(f\"tp: {tp} \\ntn: {tn} \\nfp: {fp} \\nfn: {fn}\")\n",
    "    \"\"\"\n",
    "    iforest_cnf_matrix = iforest_cnf_matrix.astype('float') / \\\n",
    "            iforest_cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print(iforest_cnf_matrix)\n",
    "\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = iforest_cnf_matrix.ravel()\n",
    "    print(f\"Normalized \\ntp: {tp} \\ntn: {tn} \\nfp: {fp} \\nfn: {fn}\")\n",
    "    \"\"\"\n",
    "    depths = iforest.get_depths(points)\n",
    "    anomalous_depths = depths[np.where(y==1.0)]\n",
    "    print(\"Average anomalous depth:\", np.mean(anomalous_depths))\n",
    "\n",
    "    non_anomalous_depths = depths[np.where(y==0.0)]\n",
    "    print(\"Average non-anomalous depth:\", np.mean(non_anomalous_depths))\n",
    "    return (scores, depths, y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning plane fit...\n",
      "done fitting\n",
      "[[ 1.   0. ]\n",
      " [ 0.5  0.5]]\n",
      "Average anomalous depth: 10.88\n",
      "Average non-anomalous depth: 25.6531052632\n",
      "\n",
      "Done plane simul-----\n",
      "\n",
      "Beginning iforest fit...\n",
      "done fitting\n",
      "[[ 1.   0. ]\n",
      " [ 0.5  0.5]]\n",
      "Average anomalous depth: 9.368\n",
      "Average non-anomalous depth: 20.3250842105\n"
     ]
    }
   ],
   "source": [
    "n = 1000 # number of entries\n",
    "p = 2    # features\n",
    "\n",
    "infection_pct = 0.05\n",
    "X, y = _gen_easy_data(n, p, infection_pct)\n",
    "\n",
    "scores_r, depths_r, y_pred_r, y_r = run_plane_simul(X, y)\n",
    "print(\"\\nDone plane simul-----\\n\")\n",
    "scores_i, depths_i, y_pred_i, y_i = run_iforest_simul(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.57465909e+00,   8.56434098e+00],\n",
       "       [  5.68247247e+00,  -4.04386367e+00],\n",
       "       [  3.29215027e-01,   1.29935858e+01],\n",
       "       [  4.21284127e+00,   4.41438584e+00],\n",
       "       [  6.26269186e+00,  -1.38089816e+00],\n",
       "       [  1.92749598e+01,   3.66927921e+00],\n",
       "       [ -1.00043148e+00,  -9.14574224e+00],\n",
       "       [  1.58880489e+01,   2.39339553e+01],\n",
       "       [  4.27565851e+00,   1.69675957e+01],\n",
       "       [ -5.50948703e+00,  -8.79222198e-01],\n",
       "       [  5.36613107e+00,   2.66032836e-01],\n",
       "       [  5.27617031e+00,   1.34412185e+01],\n",
       "       [  1.47605715e+00,   8.37471240e-01],\n",
       "       [  2.86397056e+01,   2.58300135e+01],\n",
       "       [  5.01329910e+00,   1.62176145e+01],\n",
       "       [  1.50639108e+01,  -1.69728966e+00],\n",
       "       [  1.66043824e+01,   3.81643983e+00],\n",
       "       [  6.29731429e+00,   5.88248035e+00],\n",
       "       [  6.43350507e+00,   1.82696068e+01],\n",
       "       [  1.72926924e+01,  -1.44294323e+01],\n",
       "       [  5.87453366e+00,   2.61395326e+00],\n",
       "       [  5.34197127e+00,  -4.98685654e+00],\n",
       "       [  1.51479924e-01,   1.57972976e+01],\n",
       "       [ -3.22936039e+00,   1.14153441e+01],\n",
       "       [  7.80672227e+00,   1.05228755e+00],\n",
       "       [  2.55900789e+00,   1.42826491e+01],\n",
       "       [  5.12151731e+00,  -3.28103622e+00],\n",
       "       [  1.62405977e+01,  -7.60604481e+00],\n",
       "       [  4.53663215e+00,   6.15176463e+00],\n",
       "       [  4.43709306e+00,   2.49283710e+00],\n",
       "       [  2.51256136e+00,   6.30541344e+00],\n",
       "       [ -9.39865741e+00,   1.41730789e+00],\n",
       "       [  1.45751874e+01,   8.31961006e+00],\n",
       "       [  1.08710352e+01,   1.31500731e+01],\n",
       "       [  5.13402856e+00,   1.46072916e+01],\n",
       "       [  6.19554982e+00,   1.39980127e+01],\n",
       "       [ -3.09596212e+00,   2.27968331e+01],\n",
       "       [  1.88466152e+01,   2.67535370e-02],\n",
       "       [ -6.60202205e+00,   2.34247865e+01],\n",
       "       [  2.85539187e+00,   1.51764632e+01],\n",
       "       [  1.82368531e+01,  -1.56083919e+01],\n",
       "       [  1.08919475e+01,   9.37687172e+00],\n",
       "       [  1.11736254e+01,  -1.23134554e+01],\n",
       "       [  9.22995800e+00,   3.20667559e+00],\n",
       "       [  4.33403713e+00,   1.53558155e+01],\n",
       "       [  1.07164624e+01,   2.16488232e+01],\n",
       "       [  4.37386150e+00,   6.69159557e+00],\n",
       "       [  1.39826306e+01,  -8.35404078e+00],\n",
       "       [  9.83081027e+00,   3.86152592e+00],\n",
       "       [  1.10178082e+01,   1.53224352e+01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[np.where(y==1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rhp = RandomHyperplanes(n_estimators=N_ESTIMATORS)\n",
    "rhp = rhp.fit(X)\n",
    "depths = rhp.get_depths(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.79   6.41   6.64   6.77   7.08   7.14   7.15   7.34   7.99   8.05\n",
      "   8.25   8.37   8.5    8.76   9.03   9.46   9.47   9.58   9.64   9.89\n",
      "  10.35  10.43  10.5   11.23  11.24  11.25  11.99  12.08  12.14  12.23\n",
      "  12.42  12.45  12.59  12.66  12.76  12.78  12.9   13.03  13.11  13.17\n",
      "  13.23  13.34  13.93  13.94  14.01  14.13  14.23  14.31  14.61  14.67\n",
      "  14.88  14.92  15.44  15.47  15.72  15.8   15.93  16.    16.04  16.09\n",
      "  16.35  16.46  16.62  16.67  17.05  17.19  17.28  17.38  17.52  17.6\n",
      "  17.79  17.81  17.92  18.01  18.04  18.08  18.2   18.21  18.25  18.48\n",
      "  18.67  18.74  18.77  18.93  19.    19.01  19.07  19.12  19.13  19.14\n",
      "  19.2   19.22  19.25  19.31  19.37  19.38  19.56  19.7   19.75  19.79\n",
      "  19.8   19.87  19.95  19.99  20.03  20.06  20.13  20.14  20.17  20.2\n",
      "  20.28  20.29  20.35  20.38  20.42  20.49  20.54  20.55  20.56  20.58\n",
      "  20.63  20.66  20.72  20.76  20.85  20.94  20.96  20.97  20.98  21.    21.1\n",
      "  21.18  21.2   21.22  21.24  21.27  21.29  21.35  21.37  21.38  21.39\n",
      "  21.41  21.46  21.53  21.59  21.62  21.64  21.65  21.67  21.7   21.76\n",
      "  21.78  21.89  21.93  22.    22.01  22.03  22.06  22.07  22.11  22.12\n",
      "  22.13  22.16  22.18  22.19  22.23  22.25  22.28  22.33  22.36  22.38\n",
      "  22.4   22.41  22.44  22.49  22.58  22.62  22.65  22.67  22.71  22.73\n",
      "  22.75  22.77  22.78  22.79  22.83  22.84  22.85  22.88  22.89  22.91\n",
      "  22.96  22.98  22.99  23.01  23.07  23.09  23.1   23.11  23.14  23.18\n",
      "  23.19  23.21  23.22  23.23  23.26  23.3   23.35  23.36  23.37  23.41\n",
      "  23.46  23.48  23.49  23.5   23.51  23.54  23.62  23.67  23.69  23.76\n",
      "  23.8   23.83  23.84  23.85  23.86  23.88  23.89  23.9   23.94  23.96\n",
      "  23.99  24.01  24.02  24.06  24.07  24.08  24.1   24.11  24.12  24.14\n",
      "  24.16  24.17  24.22  24.23  24.24  24.25  24.29  24.32  24.33  24.34\n",
      "  24.36  24.38  24.41  24.43  24.45  24.47  24.49  24.5   24.51  24.52\n",
      "  24.54  24.56  24.58  24.6   24.61  24.62  24.64  24.66  24.68  24.7\n",
      "  24.71  24.72  24.73  24.76  24.78  24.79  24.8   24.81  24.82  24.83\n",
      "  24.86  24.89  24.9   24.93  24.96  24.99  25.    25.03  25.04  25.05\n",
      "  25.07  25.09  25.1   25.11  25.12  25.14  25.15  25.18  25.19  25.22\n",
      "  25.23  25.24  25.25  25.27  25.28  25.31  25.34  25.36  25.37  25.38\n",
      "  25.4   25.43  25.44  25.48  25.49  25.5   25.52  25.53  25.56  25.57\n",
      "  25.58  25.59  25.61  25.62  25.63  25.64  25.66  25.67  25.69  25.71\n",
      "  25.72  25.73  25.74  25.75  25.76  25.77  25.79  25.81  25.82  25.83\n",
      "  25.84  25.86  25.87  25.88  25.89  25.9   25.92  25.94  25.95  25.97\n",
      "  25.98  25.99  26.    26.01  26.03  26.08  26.09  26.1   26.11  26.13\n",
      "  26.15  26.16  26.17  26.18  26.19  26.2   26.21  26.22  26.24  26.25\n",
      "  26.26  26.27  26.29  26.3   26.31  26.32  26.34  26.35  26.36  26.37\n",
      "  26.38  26.39  26.4   26.41  26.42  26.43  26.44  26.45  26.46  26.47\n",
      "  26.48  26.49  26.5   26.51  26.53  26.54  26.55  26.56  26.58  26.59\n",
      "  26.6   26.62  26.64  26.65  26.66  26.68  26.69  26.7   26.71  26.73\n",
      "  26.74  26.75  26.76  26.77  26.79  26.8   26.81  26.83  26.84  26.85\n",
      "  26.86  26.87  26.88  26.89  26.9   26.92  26.93  26.98  26.99  27.    27.01\n",
      "  27.02  27.03  27.04  27.05  27.06  27.07  27.08  27.1   27.11  27.12\n",
      "  27.13  27.15  27.16  27.17  27.19  27.2   27.21  27.24  27.26  27.28\n",
      "  27.29  27.3   27.31  27.32  27.33  27.35  27.36  27.37  27.38  27.39\n",
      "  27.4   27.41  27.42  27.43  27.45  27.46  27.51  27.52  27.53  27.54\n",
      "  27.57  27.58  27.59  27.62  27.64  27.67  27.68  27.69  27.71  27.72\n",
      "  27.75  27.77  27.78  27.79  27.81  27.82  27.83  27.84  27.85  27.86\n",
      "  27.89  27.9   27.91  27.92  27.93  27.94  27.95  27.96  27.97  27.98\n",
      "  28.01  28.03  28.04  28.05  28.06  28.07  28.08  28.09  28.11  28.12\n",
      "  28.13  28.14  28.15  28.16  28.17  28.18  28.19  28.2   28.21  28.22\n",
      "  28.23  28.24  28.25  28.26  28.29  28.31  28.32  28.33  28.34  28.35\n",
      "  28.36  28.38  28.39  28.4   28.43  28.44  28.45  28.46  28.47  28.48\n",
      "  28.49  28.5   28.51  28.52  28.53  28.54  28.55  28.56  28.57  28.58\n",
      "  28.59  28.6   28.61  28.62  28.65  28.66  28.68  28.7   28.73  28.74\n",
      "  28.75  28.76  28.77  28.78  28.79  28.8   28.81  28.82  28.83  28.85\n",
      "  28.86  28.87  28.88  28.89  28.9   28.91  28.94  28.95  28.96  28.97\n",
      "  28.99  29.    29.02  29.04  29.05  29.07  29.08  29.09  29.1   29.13\n",
      "  29.16  29.17  29.18  29.19  29.2   29.21  29.22  29.27  29.28  29.29\n",
      "  29.32  29.33  29.34  29.37  29.38  29.4   29.41  29.42  29.45  29.46\n",
      "  29.47  29.49  29.5   29.52  29.53  29.56  29.58  29.59  29.6   29.76\n",
      "  29.88  29.94  29.95  29.97  29.98  30.01  30.02  30.03  30.08  30.11\n",
      "  30.12  30.14  30.16  30.18  30.21  30.23  30.26  30.27  30.3   30.33\n",
      "  30.35  30.36  30.37  30.39  30.41  30.43  30.5   30.52  30.53  30.55\n",
      "  30.67  30.68  30.78  30.83  30.85  31.14  31.23]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(depths))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
